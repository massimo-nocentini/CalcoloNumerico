\section{Before Partial Pivoting}

\begin{exercise}[3.6]
Per il testo dell'esercizio consultare il libro di testo.
\end{exercise}
\begin{proof}
Il numero di operazioni che compio \`e dato da:
\begin{displaymath}
\sum_{i = 1}^{n - i}{\left( (n-i) + 2(n-i) \right)} =
\sum_{k = 1}^{n - 1}{\left( k + 2k^{2} \right)} = \frac{n(n-1)}{2} +
\frac{2(n-1)n(2n-1)}{6} \approx \frac{2}{3}n^{3}
\end{displaymath}
\end{proof}

\begin{exercise}[3.9, Lemma 3.4]
Se $A$ \`e diagonale dominante per righe allora lo sono anche tutte le sue
sotto-matrici principali.
\end{exercise}
\begin{proof}
Per ipotesi $A$ \`e diagonale dominante per righe, quindi posso costruire questa 
disuguaglianza:
\begin{displaymath}
|a_{ii}| > \sum_{j = 1 \\j \not = i}^{n}{|a_{ij}|} \geq \sum_{j = 1 \\j \not =
i}^{k}{|a_{ij}|}, \quad k \leq n
\end{displaymath}
con $k$ indice della sotto-matrice di ordine $k$. La disuguaglianza a destra
dimostra l'asserto e la prova \`e terminata.
\end{proof}

\begin{exercise}[3.9, Lemma 3.5]
$A$ \`e diagonale dominante per righe sse $A^{T}$ \`e diagonale dominante per
colonne.
\end{exercise}
\begin{proof}[Proof of $\Rightarrow$]
Per ipotesi $A$ \`e diagonale dominante per righe, ovvero:
\begin{displaymath}
|a_{ii}| > \sum_{j = 1 \\j \not = i}^{n}{|a_{ij}|}
\end{displaymath}
Costruisco la trasposta: se $a_{ij} \in A$ allora $a_{ji} \in A^{T}$. Riscrivo
la definizione precedente:
\begin{displaymath}
|a_{ii}| > \sum_{j = 1 \\j \not = i}^{n}{|a_{ji}|}
\end{displaymath}
Ma questa \`e la definizione di matrice diagonale dominante per colonne e questo
termina la prova.
\end{proof}

\begin{proof}[Proof of $\Leftarrow$]
Con argomento simmetrico si dimostra anche l'implicazione inversa.
\end{proof}

\begin{exercise}[3.10]
Se $A = LDL^{T}$ allora $A$ \`e sdp.
\end{exercise}
\begin{proof}
Devo dimostrare che $A$ soddisfa la definizione sdp:
\begin{itemize}
\item $A = LDL^{T} = (L^{T})^{T}DL^{T} = LDL^{T} = A^{T}$, quindi $A$ \`e
simmetrica.
\item $\forall \vect{x} \in \mathbb{R}^{n}, \vect{x} \not = \vect{0}$ allora
deve valere:
\begin{displaymath}
\vect{x}^{T}A\vect{x} = \vect{x}^{T}LDL^{T}\vect{x} > 0
\end{displaymath}
Costruisco il vettore $\vect{y} = L^{T}\vect{x}$, di conseguenza $\vect{y}^{T}
= \vect{x}^{T}(L^{T})^{T} = \vect{x}^{T}L$. Quindi posso riscrivere
$\vect{y}^{T}D\vect{y} > 0$. Rappresento il prodotto $\vect{y}^{T}(D\vect{y})$:
\begin{displaymath}
\vect{y}^{T}(D\vect{y}) = 
\begin{bmatrix}
y_{1} & \cdots & y_{n}
\end{bmatrix}
\begin{bmatrix}
d_{11} \\
 & d_{22} \\
 & 		& \ddots \\
 & 		&		& \ddots\\
 &  	&  		&		& d_{nn}
\end{bmatrix}
\begin{bmatrix}
y_{1}\\
\vdots \\
y_{n}
\end{bmatrix} = 
\begin{bmatrix}
y_{1} & \cdots & y_{n}
\end{bmatrix}
\begin{bmatrix}
y_{1}d_{11}\\
\vdots \\
y_{n}d_{nn}
\end{bmatrix} =
\sum_{i = 1}^{n}{y_{i}d_{ii}} \geq 0
\end{displaymath} 
In quanto per ipotesi $d_{ii} > 0$. Per avere la somma uguale a 0, si dovrebbe
avere $\vect{y} = \vect{0}$. Ma questo non \`e possibile in quanto $\vect{y}  
= L^{T}\vect{x}$ con $L$ non singolare e $\vect{x} \not = \vect{0}$ per
definizione di sdp. Quindi si ha:
\begin{displaymath}
\sum_{i = 1}^{n}{y_{i}d_{ii}} > 0
\end{displaymath} 
questo \`e quanto richiesta dalla definizione di sdp, quindi $A$ \`e sdp e
questo termina la prova.
\end{itemize}
\end{proof}

\begin{exercise}[3.11]
\label{exercise:311}
Se $A$ \`e non singolare allora $A^{T}A$ e $AA^{T}$ sono sdp.
\end{exercise}
\begin{proof}
Devo verifica che $B = A^{T}A$ sia sdp quindi:
\begin{itemize}
  \item $B = A^{T}A = A^{T}(A^{T})^{T} = A^{T}A = B^{T}$, quindi $B$ \`e
  simmetrica
  \item $\forall \vect{x} \in \mathbb{R}^{n}, \vect{x} \not = \vect{0}$ allora
deve valere:
\begin{displaymath}
\vect{x}^{T}B\vect{x} = \vect{x}^{T}A^{T}A\vect{x} > 0
\end{displaymath}
Costruisco il vettore $\vect{y} = A\vect{x}$, di conseguenza $\vect{y}^{T}
= \vect{x}^{T}A^{T}$. Quindi posso riscrivere
$\vect{y}^{T}\vect{y} > 0$ e rappresento:
\begin{displaymath}
\vect{y}^{T}\vect{y} = 
\begin{bmatrix}
y_{1} & \cdots & y_{n}
\end{bmatrix}
\begin{bmatrix}
y_{1}\\
\vdots \\
y_{n}
\end{bmatrix} =
\sum_{i = 1}^{n}{y_{i}^{2}} \geq 0
\end{displaymath} 
Per avere la somma uguale a 0, si dovrebbe
avere $\vect{y} = \vect{0}$. Ma questo non \`e possibile in quanto $\vect{y}  
= A\vect{x}$ con $A$ non singolare, quindi $A$ non \`e la matrice nulla, e
$\vect{x} \not = \vect{0}$ per definizione di sdp. Quindi si ha:
\begin{displaymath}
\sum_{i = 1}^{n}{y_{i}^{2}} > 0
\end{displaymath} 
questo \`e quanto richiesta dalla definizione di sdp, quindi $B$ \`e sdp.

Dato che ho dimostrato che $B$ \`e simmetrica allora anche $B^{T}$ \`e sdp e
questo termina la prova.
\end{itemize}
\end{proof}

\begin{exercise}[3.12]
Se $A \in \mathbb{R}^{m \times n}$, con $m \geq n = rank(A)$ allora $A^{T}A$ \`e
sdp.
\end{exercise}
\begin{proof}
Devo dimostrare che $B = A^{T}A$ \`e sdp.
\begin{itemize}
  \item $B$ \`e simmetrica per l'esercizio \ref{exercise:311}.
  \item $\forall \vect{x} \in \mathbb{R}^{n}, \vect{x} \not = \vect{0}$ allora
  posso costruire un vettore (come fatto nell'esercizio precedente) $\vect{y} =
  A\vect{x}, \vect{y} \in \mathbb{R}^{m}$ ed il rispettivo $\vect{y}^{T} = 
  \vect{x}^{T}A^{T}, \vect{y}^{T} \in \mathbb{R}^{1 \times m}$ e costruire il 
  prodotto richiesto dalla definizione
  \begin{displaymath}
  	\sum_{i = 1}^{m}{y_{i}^{2}} \geq 0
  \end{displaymath}
  Dato che in $A$ ci sono $m-n$ linearmente dipendenti, allora alcuni termini
  della sommatoria $y_{i}$ possono essere nulli. Ma per le ipotesi, $n =
  rank(A)$, quindi esiste un minore principale $\det(A_{k}) \not = 0$. Per come
  \`e costruito $\vect{y}$ allora $\exists i \in \mathbb{N}: y_{i} \not = 0$
  perch\`e $\det(A_{k}) \not = 0$ per ipotesi e $\vect{x} \not = \vect{0}$ per
  la definizione di sdp. Quindi la somma \`e strettamente positiva e questo
  termina la prova.
\end{itemize}
\end{proof}

\begin{exercise}[3.13]
Se $A \in \mathbb{R}^{n \times n}$ allora $A = \frac{1}{2}(A + A^{T}) +
\frac{1}{2}(A - A^{T})$
\end{exercise}
\begin{proof}
\begin{displaymath}
\begin{split}
\frac{1}{2}
\left (
\begin{bmatrix}
a_{11} & \cdots & \cdots &\cdots & a_{1n} \\
\vdots & \ddots &		&		& \vdots\\
\vdots &  		& \ddots & 		& \vdots\\
\vdots & 		&		& \ddots & \vdots\\
a_{n1} & \cdots & \cdots &\cdots & a_{nn}
\end{bmatrix} + 
\begin{bmatrix}
a_{11} & \cdots & \cdots &\cdots & a_{n1} \\
\vdots & \ddots &		&		& \vdots\\
\vdots &  		& \ddots & 		& \vdots\\
\vdots & 		&		& \ddots & \vdots\\
a_{1n} & \cdots & \cdots &\cdots & a_{nn}
\end{bmatrix} \right ) = \\
= \frac{1}{2} 
\begin{bmatrix}
2a_{11} & \cdots & \cdots &\cdots & a_{1n} + a_{n1} \\
\vdots & \ddots &		&		& \vdots\\
\vdots &  		& \ddots & 		& \vdots\\
\vdots & 		&		& \ddots & \vdots\\
a_{n1} + a_{1n} & \cdots & \cdots &\cdots & 2a_{nn}
\end{bmatrix} = A^{s}
\end{split}
\end{displaymath}
La matrice $A_{s}$ \`e una matrice simmetrica.

Analogamente per la differenza:
\begin{displaymath}
\begin{split}
\frac{1}{2}
\left (
\begin{bmatrix}
a_{11} & \cdots & \cdots &\cdots & a_{1n} \\
\vdots & \ddots &		&		& \vdots\\
\vdots &  		& \ddots & 		& \vdots\\
\vdots & 		&		& \ddots & \vdots\\
a_{n1} & \cdots & \cdots &\cdots & a_{nn}
\end{bmatrix} - 
\begin{bmatrix}
a_{11} & \cdots & \cdots &\cdots & a_{n1} \\
\vdots & \ddots &		&		& \vdots\\
\vdots &  		& \ddots & 		& \vdots\\
\vdots & 		&		& \ddots & \vdots\\
a_{1n} & \cdots & \cdots &\cdots & a_{nn}
\end{bmatrix} \right ) = \\
= \frac{1}{2} 
\begin{bmatrix}
0 & \cdots & \cdots &\cdots & a_{1n} - a_{n1} \\
\vdots & \ddots &		&		& \vdots\\
\vdots &  		& \ddots & 		& \vdots\\
\vdots & 		&		& \ddots & \vdots\\
a_{n1} - a_{1n}& \cdots & \cdots &\cdots & 0
\end{bmatrix} = A^{a}
\end{split}
\end{displaymath}
Verifico che $A_{s} + A_{a} = A$:
\begin{displaymath}
\begin{split}
A_{s} + A_{a} = 
\frac{1}{2}
\begin{bmatrix}
2a_{11} & \cdots & \cdots &\cdots & a_{1n} + a_{n1} + a_{1n} - a_{n1}\\
\vdots & \ddots &		&		& \vdots\\
\vdots &  		& \ddots & 		& \vdots\\
\vdots & 		&		& \ddots & \vdots\\
a_{n1} + a_{1n} + a_{n1} - a_{1n} & \cdots & \cdots &\cdots & 2a_{nn}
\end{bmatrix} = \\
= \frac{1}{2}
\begin{bmatrix}
2a_{11} & \cdots & \cdots &\cdots & 2a_{1n}\\
\vdots & \ddots &		&		& \vdots\\
\vdots &  		& \ddots & 		& \vdots\\
\vdots & 		&		& \ddots & \vdots\\
2a_{n1}& \cdots & \cdots &\cdots & 2a_{nn}
\end{bmatrix} = 
\begin{bmatrix}
a_{11} & \cdots & \cdots &\cdots & a_{1n} \\
\vdots & \ddots &		&		& \vdots\\
\vdots &  		& \ddots & 		& \vdots\\
\vdots & 		&		& \ddots & \vdots\\
a_{n1} & \cdots & \cdots &\cdots & a_{nn}
\end{bmatrix} = A
\end{split}
\end{displaymath}
In generale vale $a'_{ij} = a_{ij} + a_{ji} + a_{ij} - a_{ji} = 2a_{ij}$.
L'uguaglianza \`e verificata e questo termina la prova.
\end{proof}
