\section{Utility functions}
\subsection{invokeDelegate}
\lstinputlisting{listings/chapterTwo/invokeDelegate.m}

\subsection{prepareForPlottingMethodSegments}
\lstinputlisting{listings/chapterTwo/prepareForPlottingMethodSegments.m}

\subsection{prepareForPlottingSecantMethodSegments}
\lstinputlisting{listings/chapterTwo/prepareForPlottingSecantMethodSegments.m}

\subsection{errorMonitor}
\lstinputlisting{listings/chapterTwo/errorMonitor.m}

\section{Metodo di bisezione}
\label{sec:bisectionIterativeMethod}
\lstinputlisting{listings/chapterTwo/bisectionMethod.m}

\section{Metodo di Newton}
\label{sec:newtonIterativeMethod}
Questa implementazione utilizza il criterio di arresto esposto nell'
\emph{Osservazione 2.3} nel caso di radici semplici.

Una osservazione sul numero di passi effettuati: per la mia implementazione
vale $i = length(ascisse) + 2$ in quanto nel ciclo \emph{while} colleziono
$length(ascisse)$ valori, pi\`u uno per il valore di innesco iniziale, pi\`u uno
per l'ultimo valore appena usciti dal ciclo \emph{while}.

L'implementazione di questo oggetto matematico permette di specificare il
criterio di arresto da utilizzare. Sono disponibili due criteri, quello per
\emph{incremento} e per \emph{residuo}. Ho introdotto la possibilit\`a di
scegliere fra due criteri di arresto in quanto se si utilizza l'implementazione
proposta (criterio del \emph{residuo}) si va in contro al fenomeno della
cancellazione numerica, in quanto $x_{i+1} \approx x_{i}$ per $i \rightarrow
\infty$ (vedere esercizio \ref{exercise:numericalEraseExercise}). Per questo
motivo implemento un secondo criterio di arresto, per \emph{residuo}, basandomi
sull'idea dell'equazione $(2.14)$ e sull'\emph{Osservazione 2.3}, ottengo:
\begin{displaymath}
\frac{\frac{f(x_{i})}{f'(x_{i})}}{rtol_{X}|x_{i + 1}| + tol_{X}} \leq 1
\end{displaymath}
Questo criterio risulta essere pi\`u robusto dal punto di vista implementativo:
\begin{itemize}
  \item usando il rapporto $\frac{f}{f'}$ si ha un'operazione di macchina sempre
  ben condizionata ($k = 2$ per l'equazione del testo $(1.25)$), mentre usando
  la differenza introdurrei nella valutazione del criterio di arresto un errore
  con un alto fattore di amplificazione.
  \item la somma al denominatore risulta sempre ben condizionata, per\`o \`e
  importante eseguire la somma con l'ordine degli addendi scritto nella
  precedente equazione. Questo permette di perdere cifre significative quando il
  primo operando \`e molto piccolo.
\end{itemize}
\lstinputlisting{listings/chapterTwo/newtonMethod.m}

\section{Varianti del metodo di Newton}

\subsection{Molteplicit\`a dello zero nota}
\label{subsec:newtonMethodMultKnown}
Questa implementazione utilizza il criterio di arresto esposto nell'
\emph{Osservazione 2.3} nel caso di radici semplici. 

Utilizza il criterio di arresto per \emph{incremento}.
\lstinputlisting{listings/chapterTwo/newtonMethodMoltKnown.m}

\subsection{Molteplicit\`a dello zero non nota - variante Aitken}
\label{subsec:newtonMethodAitken}
Questa implementazione utilizza il criterio di arresto esposto nell'
\emph{Osservazione 2.3} nel caso di radici semplici.

Utilizza il criterio di arresto per \emph{incremento}.
\lstinputlisting{listings/chapterTwo/newtonMethodAitken.m}

\section{Metodi quasi-Newton}
\subsection{Metodo delle corde}
\label{subsec:chordMethodLinearCriteria}
Questa implementazione utilizza il criterio di arresto esposto nell'
\emph{Osservazione 2.3} nel caso ordine di convergenza $p = 1$, ovvero il
criterio di arresto sar\`a dato da:
\begin{displaymath}
	|x_{i+1} - x_{i}| \leq \frac{1-c}{c}tol_{X}
\end{displaymath}
Ricavo in modo dinamico la costante $c$, usando le tre iterate pi\`u recenti:
\begin{displaymath}
	c \approx \frac{|x_{i} - x_{i-1}|}{|x_{i-1} - x_{i-2}|}
\end{displaymath}
\lstinputlisting{listings/chapterTwo/chordMethodLinearCriteria.m}
\begin{oss}
Questa implementazione non \`e molto robusta in quanto mancano molti controlli
per garantire il significato di tutte le operazioni di divisione. Dovrebbero
essere aggiunti. Se si prova ad eseguire questa applicazione:
\begin{lstlisting}
[x, i, ascisse] =
chordMethodLinearCriteria('functionNewtonRecursion','functionNewtonRecursionDerivative',1-1e-10,1e5, 1e-15, 1e-15)
\end{lstlisting}
si ottiene una serie infinita di messaggi ``\emph{Warning: division by zero}''.
\\\\
Inoltre sarebbe interessante confrontare il criterio di arresto usato
nell'implementazione con il criterio di arresto usato invece per
l'implementazione del metodo \nameref{sec:newtonIterativeMethod}.
\end{oss}

\subsection{Metodo delle secanti}
\label{subsec:secantMethod}
Questa implementazione utilizza il criterio di arresto esposto nell'
\emph{Osservazione 2.3} nel caso di radici semplici.

Utilizza il criterio di arresto per \emph{incremento}.
\lstinputlisting{listings/chapterTwo/secantMethod.m}

\section{Script}
\subsection{Script eser 2.5}
\label{subsec:ScriptEser25}
\lstinputlisting{listings/chapterTwo/scriptExercise25.m}

\subsection{Script eser 2.5 - Newton Stop Criteria Comparison}
\label{subsec:ScriptEser25NewtonStopCriteriaComparison}
\lstinputlisting{listings/chapterTwo/scriptExercise25NewtonComparison.m}

\subsection{Script eser 2.7}
\label{subsec:ScriptEser27}
\lstinputlisting{listings/chapterTwo/scriptExercise27.m}
